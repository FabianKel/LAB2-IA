{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LINK DE REPOSITORIO\n",
    "https://github.com/FabianKel/LAB2-IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TASK #1 - Preguntas Teóricas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué el modelo de Naive Bayes se le considera “naive”?\n",
    "\n",
    "- El modelo se considera naive debido a que asume que las características de medición son independientes entre sí y contribuyen por igual en el momento de dar resultado. Esta suposición de independencia es rara vez es cierta. Sin embargo, permite que el modelo sea muy eficiente en términos de tiempo de computación y memoria.\n",
    "\n",
    "### Explique la formulación matemática que se busca optimizar en Support Vector Machine, además responda ¿cómo funciona el truco del Kernel para este modelo? (Lo que se espera de esta pregunta es que puedan explicar en sus propias palabras la fórmula a la que llegamos que debemos optimizar de SVM en clase)\n",
    "\n",
    "- La formulación matemática que se busca optimizar en Support Vector Machine (SVM) es maximizar el margen entre las clases o bien como fue mencionado en clase crear una frontera para separar las diferentes clases con las que estamos logrando. Esto se logra resolviendo el problema de optimización cuadrática donde se aseguran que los datos estén correctamente clasificados y fuera del margen. La función es:\n",
    "\n",
    "$$\\min_{(\\mathbf{w}, b)} \\frac{1}{2} \\|\\mathbf{w}\\|^2$$\n",
    "\n",
    "sujeto a:\n",
    "\n",
    "$$y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1 \\quad \\forall i$$\n",
    "\n",
    "donde $\\mathbf{w}$ es el vector de pesos, $b$ es el sesgo, $\\mathbf{x}_i$ son los vectores de características y $y_i$ son las etiquetas de clase.\n",
    "\n",
    "- El truco del Kernel permite a SVM manejar datos no linealmente separables al transformar los datos originales a un espacio de mayor dimensión donde es más probable que sean linealmente separables. Esto se hace utilizando una función de kernel \\(K(\\mathbf{x}_i, \\mathbf{x}_j)\\) que va calcula el producto punto en el espacio transformado sin necesidad de calcular explícitamente la transformación.\n",
    "### Investigue sobre Random Forest y responda\n",
    "1. ¿Qué tipo de ensemble learning es este modelo?\n",
    "    - El tipo de ensemble learning es Bagging (Bootstrap Aggregating).\n",
    "\n",
    "2. ¿Cuál es la idea general detrás de Random Forest?\n",
    "    - La idea general detrás de Random Forest es construir múltiples árboles de decisión durante el entrenamiento y clasificación o la media de las predicciones (regresión) de los árboles individuales. Cada árbol es entrenado con una muestra aleatoria del dataset original con reemplazo (bootstrap sample), y en cada nodo de los árboles, solo un subconjunto aleatorio de características es considerado para la división.\n",
    "\n",
    "3. ¿Por qué se busca baja correlación entre los árboles de Random Forest?\n",
    "    - Se busca baja correlación entre los árboles de Random Forest porque si los árboles son altamente correlacionados, sus errores también serán correlacionados, lo que reduce la efectividad del ensemble. La baja correlación asegura que los errores de los árboles individuales se cancelen entre sí, mejorando la precisión y robustez del modelo final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TASK #2 - Naive Bayes: Clasificador de Mensajes Ham/Spam**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de Archivo a Utilizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 15 mensajes del dataset:\n",
      "ham: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "ham: Ok lar... Joking wif u oni...\n",
      "\n",
      "spam: Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "ham: U dun say so early hor... U c already then say...\n",
      "\n",
      "ham: Nah I don't think he goes to usf, he lives around here though\n",
      "\n",
      "spam: FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
      "\n",
      "ham: Even my brother is not like to speak with me. They treat me like aids patent.\n",
      "\n",
      "ham: As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "\n",
      "spam: WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "\n",
      "spam: Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n",
      "ham: I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
      "\n",
      "spam: SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
      "\n",
      "spam: URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
      "\n",
      "ham: I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
      "\n",
      "ham: I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "    messages = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            label, message = line.strip().split('\\t', 1)\n",
    "            messages.append(message)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return messages, labels\n",
    "\n",
    "# Cargar el dataset\n",
    "messages, labels = load_dataset('entrenamiento.txt')\n",
    "\n",
    "print(\"Primeros 15 mensajes del dataset:\")\n",
    "for msg, label in zip(messages[:15], labels[:15]):\n",
    "    print(f\"{label}: {msg}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesar Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "Texto procesado: ['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar caracteres especiales\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenización simple por espacios\n",
    "    return text.split()\n",
    "\n",
    "# Ejemplo la función de preprocesamiento\n",
    "texto = messages[0]\n",
    "print(\"Texto original:\", texto)\n",
    "print(\"Texto procesado:\", preprocess_text(texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset dividido en training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 4452\n",
      "Tamaño del conjunto de prueba: 1113\n"
     ]
    }
   ],
   "source": [
    "# Training y Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    messages, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(X_train)}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades de clase: {'ham': 0.8688230008984726, 'spam': 0.13117699910152741}\n",
      "\n",
      "Tamaño del vocabulario: 7661\n"
     ]
    }
   ],
   "source": [
    "def TrainNaive_bayes(messages, labels, alpha=1.0):\n",
    "\n",
    "    # contadores\n",
    "    WordCounts = defaultdict(lambda: defaultdict(int))\n",
    "    ClassCounts = defaultdict(int)\n",
    "    Vocabulary = set()\n",
    "    \n",
    "    # Contar ocurrencias de palabras y clases\n",
    "    for message, label in zip(messages, labels):\n",
    "        ClassCounts[label] += 1\n",
    "        words = preprocess_text(message)\n",
    "        \n",
    "        for word in words:\n",
    "            WordCounts[label][word] += 1\n",
    "            Vocabulary.add(word)\n",
    "    \n",
    "    # Calcular probabilidades de clase\n",
    "    TotalDocs = len(messages)\n",
    "    ClassProbs = {\n",
    "        label: count/TotalDocs \n",
    "        for label, count in ClassCounts.items()\n",
    "    }\n",
    "    \n",
    "    # Calcular probabilidades de palabras con suavizado de Laplace\n",
    "    vocab_size = len(Vocabulary)\n",
    "    word_probs = {}\n",
    "    \n",
    "    for label in ClassCounts.keys():\n",
    "        total_words = sum(WordCounts[label].values())\n",
    "        word_probs[label] = {}\n",
    "        \n",
    "        for word in Vocabulary:\n",
    "            numerator = WordCounts[label][word] + alpha\n",
    "            denominator = total_words + alpha * vocab_size\n",
    "            word_probs[label][word] = numerator / denominator\n",
    "    \n",
    "    return word_probs, ClassProbs, Vocabulary\n",
    "\n",
    "# Entrenamos el modelo\n",
    "word_probs, ClassProbs, Vocabulary = TrainNaive_bayes(X_train, y_train)\n",
    "\n",
    "print(\"Probabilidades de clase:\", ClassProbs)\n",
    "print(\"\\nTamaño del vocabulario:\", len(Vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TASK #3 - Clasificación de Partidas de League of Legends**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Referencias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué es Support Vector Machine? (2024, octubre 4). Ibm.com. https://www.ibm.com/mx-es/topics/support-vector-machine\n",
    "\n",
    "susmit_sekhar_bhakta Follow Improve. (2024, febrero 22). Random Forest algorithm in machine learning. GeeksforGeeks. https://www.geeksforgeeks.org/random-forest-algorithm-in-machine-learning/\n",
    "\n",
    "What is random forest? (2024, diciembre 19). Ibm.com. https://www.ibm.com/think/topics/random-forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
